# Sistema Clasificador de Etapas Procesales Laborales
## Tesis LexGO - Prototipo ML

Sistema hÃ­brido que combina Machine Learning tradicional (TF-IDF + Random Forest) con generaciÃ³n de timelines para causas laborales de CABA/Buenos Aires.

---

## ğŸ“‹ Requisitos Previos

### Python 3.8+

### LibrerÃ­as necesarias:
```bash
pip install pypdf2 pandas scikit-learn matplotlib seaborn
```

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
lexgo-ml-tesis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # PDFs descargados (input)
â”‚   â”œâ”€â”€ processed/              # Datasets procesados
â”‚   â””â”€â”€ sentencias_etiquetadas.csv  # Etiquetas manuales
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vectorizer.pkl          # Modelo TF-IDF entrenado
â”‚   â””â”€â”€ clasificador.pkl        # Random Forest entrenado
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.png    # VisualizaciÃ³n de resultados
â”‚   â”œâ”€â”€ metricas.csv            # MÃ©tricas del modelo
â”‚   â””â”€â”€ *_analisis.json         # Resultados por PDF
â””â”€â”€ scripts/
    â”œâ”€â”€ etiquetar_sentencias.py
    â”œâ”€â”€ preparar_datos.py
    â”œâ”€â”€ entrenar_clasificador.py
    â”œâ”€â”€ probar_clasificador.py
    â””â”€â”€ sistema_integrado.py
```

---

## ğŸš€ Pipeline Completo (Paso a Paso)

### **FASE 1: RecolecciÃ³n y Etiquetado de Datos** (2-3 horas)

#### Paso 1.1: Descargar sentencias
- Ir a: https://www.cij.gov.ar/sentencias.html
- Buscar: "derecho laboral" en CABA
- Descargar 50 PDFs de sentencias laborales
- Guardar en: `data/raw/`

#### Paso 1.2: Etiquetar manualmente
```bash
python etiquetar_sentencias.py
```

**CategorÃ­as:**
- `1` â†’ SECLO (conciliaciÃ³n prelegal)
- `2` â†’ Demanda inicial (traslado, contestaciÃ³n)
- `3` â†’ Prueba (apertura a prueba, testimonial, pericial)
- `4` â†’ Sentencia (fallo, parte dispositiva)
- `5` â†’ Desconocido

**Output:** `data/sentencias_etiquetadas.csv`

---

### **FASE 2: PreparaciÃ³n de Datos** (5-10 minutos)

```bash
python preparar_datos.py
```

**QuÃ© hace:**
- Extrae texto completo de PDFs
- Limpia y normaliza texto
- Crea split train/test (80/20)
- Verifica balance de clases

**Output:**
- `data/processed/train.csv`
- `data/processed/test.csv`
- `data/processed/dataset_completo.csv`

---

### **FASE 3: Entrenamiento del Modelo** (2-5 minutos)

```bash
python entrenar_clasificador.py
```

**QuÃ© hace:**
- Vectoriza texto con TF-IDF (1000 features, bi-gramas)
- Entrena Random Forest (100 Ã¡rboles)
- Calcula mÃ©tricas: Accuracy, F1-Score
- Genera matriz de confusiÃ³n
- Identifica tÃ©rminos mÃ¡s importantes

**Output:**
- `models/vectorizer.pkl`
- `models/clasificador.pkl`
- `results/confusion_matrix.png`
- `results/metricas.csv`

**MÃ©tricas esperadas:**
- Accuracy: 70-85% (depende de calidad de datos)
- F1-Score: 0.65-0.80

---

### **FASE 4: Pruebas del Clasificador** (Opcional)

```bash
python probar_clasificador.py
```

**Opciones:**
1. Clasificar un PDF nuevo
2. Clasificar texto manual
3. Evaluar todos los PDFs de test

---

### **FASE 5: Sistema Integrado** (Prototipo Final)

```bash
python sistema_integrado.py
```

**Flujo completo:**
1. Usuario sube PDF
2. **Clasificador ML** identifica etapa procesal
3. **Generador** crea timeline de eventos pasados
4. **Generador** crea sugerencias de "cosas a tener en cuenta"
5. Guarda resultado en JSON

**Output:** `results/{nombre_pdf}_analisis.json`

---

## ğŸ“Š Componentes del Sistema

### 1. **Clasificador ML** (Componente AcadÃ©mico)
- **Algoritmo:** TF-IDF + Random Forest
- **Input:** Texto de documento procesal
- **Output:** Etapa + confianza
- **MÃ©tricas:** Accuracy, Precision, Recall, F1-Score

### 2. **Generador de Timeline** (Componente Funcional)
- **Input:** Etapa clasificada
- **Output:** Lista de eventos cronolÃ³gicos
- **Tipos de eventos:**
  - Hitos cumplidos
  - Plazos crÃ­ticos
  - Sugerencias y alertas

---

## ğŸ“ Para la Defensa de Tesis

### CapÃ­tulo de MetodologÃ­a:

1. **RecolecciÃ³n de datos:** 50 sentencias laborales de CABA
2. **Etiquetado manual:** 5 categorÃ­as de etapas procesales
3. **Preprocesamiento:** Limpieza, normalizaciÃ³n, train/test split
4. **Feature Engineering:** TF-IDF con bi-gramas, max 1000 features
5. **Modelo:** Random Forest (100 estimadores, depth=20)
6. **EvaluaciÃ³n:** Accuracy, F1-score, matriz de confusiÃ³n

### CapÃ­tulo de Resultados:

- **Tabla de mÃ©tricas:** Train vs Test accuracy
- **GrÃ¡fico:** Matriz de confusiÃ³n (confusion_matrix.png)
- **AnÃ¡lisis:** Feature importance (top tÃ©rminos discriminantes)
- **ComparaciÃ³n:** Baseline vs modelo entrenado

### Limitaciones a mencionar:

- Dataset pequeÃ±o (50 documentos) - prototipo inicial
- Desbalance de clases posible
- EspecÃ­fico a CABA/Buenos Aires
- Requiere mÃ¡s datos para producciÃ³n

---

## ğŸ”§ Troubleshooting

### Error: "No se pudo extraer texto del PDF"
**SoluciÃ³n:** Verificar que el PDF tenga texto seleccionable (no sea imagen escaneada)

### Error: "Desbalance de clases severo"
**SoluciÃ³n:** Etiquetar mÃ¡s documentos de las clases minoritarias

### Warning: "Accuracy < 60%"
**SoluciÃ³n:** 
- Aumentar cantidad de datos
- Verificar calidad de etiquetas
- Ajustar hiperparÃ¡metros del modelo

---

## ğŸ“ Notas para Desarrollo Futuro

### Mejoras posibles:
1. **Fine-tuning de LLM:** Usar Claude/GPT para generar texto mÃ¡s contextualizado
2. **ExtracciÃ³n de entidades:** NER para identificar actores, fechas, montos
3. **PredicciÃ³n de plazos:** ML para calcular tiempos reales por juzgado
4. **ClasificaciÃ³n multi-label:** Identificar mÃºltiples etapas en un documento
5. **Dataset pÃºblico:** Crear corpus etiquetado para la comunidad

---

## ğŸ‘¥ CrÃ©ditos

**Autora:** Mica  
**Universidad:** UADE  
**Proyecto:** LexGO - Sistema de GestiÃ³n Legal  
**AÃ±o:** 2024-2025

---

## ğŸ“„ Licencia

Este es un proyecto acadÃ©mico de tesis de grado.
